#' Generic Keras Sequential API Model Fitting Implementation
#'
#' @description
#' This function is the internal engine for fitting models generated by
#' `create_keras_sequential_spec()`. It is not intended to be called directly
#' by the user.
#'
#' @details
#' This function performs the following key steps:
#' \enumerate{
#'   \item \strong{Argument & Data Preparation:} It resolves arguments passed
#'     from `parsnip` (handling `rlang_zap` objects for unspecified arguments)
#'     and prepares the `x` and `y` data for Keras. It automatically determines
#'     the `input_shape` from `x` and, for classification, the `num_classes`
#'     from `y`.
#'   \item \strong{Dynamic Model Construction:} It builds the Keras model by
#'     sequentially processing the `layer_blocks` list.
#'     \itemize{
#'       \item The first block function \strong{must initialize the model}, typically
#'         by calling `keras3::keras_model_sequential()`.
#'       \item It checks for `num_{block_name}` arguments to repeat a block
#'         multiple times, creating a deeper stack of layers.
#'     }
#'   \item \strong{Model Compilation:} It compiles the final Keras model. The
#'     compilation arguments (optimizer, loss, metrics) can be customized by
#'     passing arguments prefixed with `compile_` (e.g., `compile_loss = "mae"`).
#'   \item \strong{Model Fitting:} It calls `keras3::fit()` to train the model on
#'     the prepared data.
#' }
#'
#' @param x A data frame or matrix of predictors.
#' @param y A vector of outcomes.
#' @param layer_blocks A named list of layer block functions. This is passed
#'   internally from the `parsnip` model specification.
#' @param epochs An integer for the number of training iterations.
#' @param learn_rate A double for the learning rate, used to configure the
#'   default Adam optimizer.
#' @param batch_size An integer for the number of samples per gradient update.
#'   This is a tunable parameter and is passed to `keras3::fit()`.
#' @param validation_split The proportion of the training data to use for
#'   the validation set.
#' @param verbose An integer for the verbosity of the fitting process (0, 1, or 2).
#' @param ... Additional arguments passed down from the model specification. These
#'   can include:
#'   \itemize{
#'     \item \strong{Layer Parameters:} Arguments for the layer blocks, prefixed
#'       with the block name (e.g., `dense_units = 64`).
#'     \item \strong{Architecture Parameters:} Arguments to control the number of
#'       times a block is repeated, in the format `num_{block_name}` (e.g.,
#'       `num_dense = 2`).
#'     \item \strong{Compile Parameters:} Arguments to customize model compilation,
#'       prefixed with `compile_` (e.g., `compile_loss = "mae"`,
#'       `compile_optimizer = "sgd"`).
#'     \item \strong{Fit Parameters:} Arguments to customize model fitting,
#'       prefixed with `fit_` (e.g., `fit_callbacks = list(...)`,
#'       `fit_class_weight = list(...)`).
#'   }
#'
#' @return A list containing the fitted model and other metadata. This list is
#'   stored in the `fit` slot of the `parsnip` model fit object. The list
#'   contains the following elements:
#'   \itemize{
#'     \item `fit`: The raw, fitted Keras model object.
#'     \item `history`: The Keras training history object.
#'     \item `lvl`: A character vector of the outcome factor levels (for
#'       classification) or `NULL` (for regression).
#'   }
#' @keywords internal
#' @export
generic_sequential_fit <- function(
  x,
  y,
  layer_blocks,
  ...
) {
  # --- 0. Argument & Data Preparation ---
  all_args <- list(...)
  learn_rate <- all_args$learn_rate %||% 0.01
  verbose <- all_args$verbose %||% 0

  # Process x input
  x_processed <- process_x(x)
  x_proc <- x_processed$x_proc
  input_shape <- x_processed$input_shape

  # Process y input
  y_processed <- process_y(y)
  y_mat <- y_processed$y_proc
  is_classification <- y_processed$is_classification
  class_levels <- y_processed$class_levels
  num_classes <- y_processed$num_classes

  # Determine default compile arguments based on mode
  default_loss <- if (is_classification) {
    if (num_classes > 2) {
      "categorical_crossentropy"
    } else {
      "binary_crossentropy"
    }
  } else {
    "mean_squared_error"
  }
  default_metrics <- if (is_classification) {
    "accuracy"
  } else {
    "mean_absolute_error"
  }

  # --- 2. Dynamic Model Architecture Construction ---
  # The model is initialized as NULL. The first layer_block is expected to
  # create the model (e.g., by defining an input layer). Subsequent blocks
  # will receive and modify the model object. The order is critical.
  model <- NULL

  for (block_name in names(layer_blocks)) {
    block_fn <- layer_blocks[[block_name]]
    block_fmls <- rlang::fn_fmls(block_fn)

    num_repeats_arg <- paste0("num_", block_name)
    num_repeats_val <- all_args[[num_repeats_arg]]
    num_repeats <- num_repeats_val %||% 1

    # Get the arguments for this specific block from `...`
    block_arg_names <- names(block_fmls)[-1] # Exclude 'model'
    user_args <- list()
    for (arg_name in block_arg_names) {
      full_arg_name <- paste(block_name, arg_name, sep = "_")
      arg_val <- all_args[[full_arg_name]]
      # Only use the argument if it was actually provided by the user
      if (!is.null(arg_val) && !inherits(arg_val, "rlang_zap")) {
        user_args[[arg_name]] <- arg_val
      }
    }

    # Combine user-provided args with the block's defaults
    block_args <- utils::modifyList(as.list(block_fmls[-1]), user_args)

    # If the block function can accept these, provide them. This is useful for
    # the user-defined input and output layers.
    if ("input_shape" %in% names(block_fmls)) {
      block_args$input_shape <- input_shape
    }
    if (is_classification && "num_classes" %in% names(block_fmls)) {
      block_args$num_classes <- num_classes
    }

    # Add the block(s) to the model
    for (i in seq_len(num_repeats)) {
      # The first argument to the block function is the model itself
      # On the first iteration, `model` will be NULL.
      call_args <- c(list(model), block_args)
      model <- rlang::exec(block_fn, !!!call_args)
    }
  }

  # --- 3. Model Compilation ---
  compile_args <- collect_compile_args(
    all_args,
    learn_rate,
    default_loss,
    default_metrics
  )
  rlang::exec(keras3::compile, model, !!!compile_args)

  # --- 4. Model Fitting ---
  fit_args <- collect_fit_args(
    x_proc,
    y_mat,
    verbose,
    all_args
  )

  # Fit the model using the constructed arguments
  history <- rlang::exec(keras3::fit, model, !!!fit_args)

  # --- 5. Return value ---
  # Per parsnip extension guidelines, the fit function should return a list
  # containing the raw model object in an element named `fit`. For
  # classification, it should also include an element `lvl` with the factor levels.
  list(
    fit = model, # The raw Keras model object
    history = history, # The training history
    lvl = class_levels # Factor levels for classification, NULL for regression
  )
}

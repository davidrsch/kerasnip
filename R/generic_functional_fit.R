#' Generic Keras Functional API Model Fitting Implementation
#'
#' @description
#' This function is the internal engine for fitting models generated by
#' `create_keras_functional_spec()`. It is not intended to be called directly
#' by the user.
#'
#' @details
#' This function performs the following key steps:
#' \enumerate{
#'   \item \strong{Argument & Data Preparation:} It resolves arguments passed
#'     from `parsnip` (handling `rlang_zap` objects for unspecified arguments)
#'     and prepares the `x` and `y` data for Keras. It automatically determines
#'     the `input_shape` from `x` and, for classification, the `num_classes`
#'     from `y`.
#'   \item \strong{Dynamic Model Construction:} It builds the Keras model graph
#'     by processing the `layer_blocks` list.
#'     \itemize{
#'       \item \strong{Connectivity:} The graph is connected by matching the
#'         argument names of each block function to the names of previously
#'         defined blocks. For example, a block `function(input_a, ...)` will
#'         receive the output tensor from the block named `input_a`.
#'       \item \strong{Repetition:} It checks for `num_{block_name}` arguments
#'         to repeat a block multiple times, creating a chain of identical
#'         layers. A block can only be repeated if it has exactly one input
#'         tensor from another block.
#'     }
#'   \item \strong{Model Compilation:} It compiles the final Keras model. The
#'     compilation arguments (optimizer, loss, metrics) can be customized by
#'     passing arguments prefixed with `compile_` (e.g., `compile_loss = "mae"`).
#'   \item \strong{Model Fitting:} It calls `keras3::fit()` to train the model
#'     on the prepared data.
#' }
#'
#' @param x A data frame or matrix of predictors.
#' @param y A vector of outcomes.
#' @param layer_blocks A named list of layer block functions. This is passed
#'   internally from the `parsnip` model specification.
#' @param epochs An integer for the number of training iterations.
#' @param learn_rate A double for the learning rate, used to configure the
#'   default Adam optimizer.
#' @param batch_size An integer for the number of samples per gradient update.
#'   This is a tunable parameter and is passed to `keras3::fit()`.
#' @param validation_split The proportion of the training data to use for the
#'   validation set.
#' @param verbose An integer for the verbosity of the fitting process (0, 1, or
#'   2).
#' @param ... Additional arguments passed down from the model specification.
#'   These can include:
#'   \itemize{
#'     \item \strong{Layer Parameters:} Arguments for the layer blocks, prefixed
#'       with the block name (e.g., `dense_units = 64`).
#'     \item \strong{Architecture Parameters:} Arguments to control the number
#'       of times a block is repeated, in the format `num_{block_name}` (e.g.,
#'       `num_dense = 2`).
#'     \item \strong{Compile Parameters:} Arguments to customize model
#'       compilation, prefixed with `compile_` (e.g., `compile_loss = "mae"`,
#'       `compile_optimizer = "sgd"`).
#'     \item \strong{Fit Parameters:} Arguments to customize model fitting,
#'       prefixed with `fit_` (e.g., `fit_callbacks = list(...)`,
#'       `fit_class_weight = list(...)`).
#'   }
#'
#' @return A list containing the fitted model and other metadata. This list is
#'   stored in the `fit` slot of the `parsnip` model fit object. The list
#'   contains the following elements:
#'   \itemize{
#'     \item `fit`: The raw, fitted Keras model object.
#'     \item `history`: The Keras training history object.
#'     \item `lvl`: A character vector of the outcome factor levels (for
#'       classification) or `NULL` (for regression).
#'   }
#' @keywords internal
#' @export
generic_functional_fit <- function(
  x,
  y,
  layer_blocks,
  ...
) {
  # --- 0. Argument & Data Preparation ---
  all_args <- list(...)
  learn_rate <- all_args$learn_rate %||% 0.01
  verbose <- all_args$verbose %||% 0

  if (is.data.frame(x) && ncol(x) == 1 && is.list(x[[1]])) {
    x_proc <- do.call(abind::abind, c(x[[1]], list(along = 0)))
  } else {
    x_proc <- as.matrix(x)
  }
  input_shape <- if (length(dim(x_proc)) > 2) dim(x_proc)[-1] else ncol(x_proc)
  is_classification <- is.factor(y)
  if (is_classification) {
    class_levels <- levels(y)
    num_classes <- length(class_levels)
    y_mat <- keras3::to_categorical(
      as.numeric(y) - 1,
      num_classes = num_classes
    )
    default_loss <- if (num_classes > 2) {
      "categorical_crossentropy"
    } else {
      "binary_crossentropy"
    }
    default_metrics <- "accuracy"
  } else {
    class_levels <- NULL
    y_mat <- as.matrix(y)
    default_loss <- "mean_squared_error"
    default_metrics <- "mean_absolute_error"
  }

  # --- 2. Dynamic Model Architecture Construction (DIFFERENT from sequential) ---
  # Create a list to store the output tensors of each block.  The names of the
  # list elements correspond to the block names.
  block_outputs <- list()
  # The first block MUST be the input layer and MUST NOT have `input_from`.
  first_block_name <- names(layer_blocks)[1]
  first_block_fn <- layer_blocks[[first_block_name]]
  block_outputs[[first_block_name]] <- first_block_fn(input_shape = input_shape)

  # Iterate through the remaining blocks, connecting and repeating them as needed.
  for (block_name in names(layer_blocks)[-1]) {
    block_fn <- layer_blocks[[block_name]]
    block_fmls <- rlang::fn_fmls(block_fn)
    block_fml_names <- names(block_fmls)

    # --- Get Repetition Count ---
    num_repeats_arg <- paste0("num_", block_name)
    num_repeats <- all_args[[num_repeats_arg]] %||% 1

    # --- Get Hyperparameters for this block ---
    # Hyperparameters are formals that are NOT other block names (graph connections)
    hyperparam_names <- setdiff(block_fml_names, names(layer_blocks))
    user_hyperparams <- list()
    for (hp_name in hyperparam_names) {
      full_arg_name <- paste(block_name, hp_name, sep = "_")
      arg_val <- all_args[[full_arg_name]]
      if (!is.null(arg_val) && !inherits(arg_val, "rlang_zap")) {
        user_hyperparams[[hp_name]] <- arg_val
      }
    }
    # Combine user args with the block's defaults for those hyperparameters
    block_hyperparams <- utils::modifyList(
      as.list(block_fmls[hyperparam_names]),
      user_hyperparams
    )

    # Add special engine-supplied arguments if the block can accept them
    if (is_classification && "num_classes" %in% block_fml_names) {
      block_hyperparams$num_classes <- num_classes
    }

    # --- Get Input Tensors for this block ---
    input_tensor_names <- intersect(block_fml_names, names(block_outputs))
    if (length(input_tensor_names) == 0 && block_name != "output") {
      warning("Block '", block_name, "' has no inputs from other blocks.")
    }

    # --- Repetition Loop ---
    if (num_repeats > 1 && length(input_tensor_names) != 1) {
      stop(
        "Block '",
        block_name,
        "' cannot be repeated because it has ",
        length(input_tensor_names),
        " inputs (",
        paste(input_tensor_names, collapse = ", "),
        "). Only blocks with exactly one input tensor can be repeated."
      )
    }

    # The initial input(s) for the first iteration
    input_args <- purrr::map(input_tensor_names, ~ block_outputs[[.x]])
    names(input_args) <- input_tensor_names

    # The tensor that will be updated and passed through the loop
    current_tensor <- input_args[[1]]

    for (i in seq_len(num_repeats)) {
      # For repetitions after the first, update the input tensor
      if (i > 1) {
        input_args[[input_tensor_names[1]]] <- current_tensor
      }
      call_args <- c(input_args, block_hyperparams)
      current_tensor <- rlang::exec(block_fn, !!!call_args)
    }

    # Store the final output of the (possibly repeated) block
    block_outputs[[block_name]] <- current_tensor
  }

  # The last layer must be named 'output'
  output_tensor <- block_outputs[["output"]]
  if (is.null(output_tensor)) {
    stop("An 'output' block must be defined in layer_blocks.")
  }
  model <- keras3::keras_model(
    inputs = block_outputs[[first_block_name]],
    outputs = output_tensor
  )

  # --- 3. Model Compilation ---
  # Collect all arguments starting with "compile_" from `...`
  compile_args <- collect_compile_args(
    all_args,
    learn_rate,
    default_loss,
    default_metrics
  )
  rlang::exec(keras3::compile, model, !!!compile_args)

  # --- 4. Model Fitting ---
  fit_args <- collect_fit_args(
    x_proc,
    y_mat,
    verbose,
    all_args
  )

  # Fit the model using the constructed arguments
  history <- rlang::exec(keras3::fit, model, !!!fit_args)

  # --- 5. Return value ---
  # Per parsnip extension guidelines, the fit function should return a list
  # containing the raw model object in an element named `fit`. For
  # classification, it should also include an element `lvl` with the factor levels.
  list(
    fit = model, # The raw Keras model object
    history = history, # The training history
    lvl = class_levels # Factor levels for classification, NULL for regression
  )
}

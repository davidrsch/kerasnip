[{"path":[]},{"path":"https://davidrsch.github.io/kerasnip/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://davidrsch.github.io/kerasnip/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://davidrsch.github.io/kerasnip/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://davidrsch.github.io/kerasnip/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://davidrsch.github.io/kerasnip/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement daviddrsch@gmail.com. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://davidrsch.github.io/kerasnip/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://davidrsch.github.io/kerasnip/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://davidrsch.github.io/kerasnip/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://davidrsch.github.io/kerasnip/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://davidrsch.github.io/kerasnip/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://davidrsch.github.io/kerasnip/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://davidrsch.github.io/kerasnip/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to kerasnip","title":"Contributing to kerasnip","text":"outlines propose change kerasnip. detailed info contributing , tidyverse packages, please see development contributing guide.","code":""},{"path":"https://davidrsch.github.io/kerasnip/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to kerasnip","text":"Small typos grammatical errors documentation may edited directly using GitHub web interface, long changes made source file. YES: edit roxygen comment .R file R/. : edit .Rd file man/.","code":""},{"path":"https://davidrsch.github.io/kerasnip/CONTRIBUTING.html","id":"prerequisites","dir":"","previous_headings":"","what":"Prerequisites","title":"Contributing to kerasnip","text":"make substantial pull request, always file issue make sure someone team agrees ’s problem. ’ve found bug, create associated issue illustrate bug minimal reprex.","code":""},{"path":"https://davidrsch.github.io/kerasnip/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"","what":"Pull request process","title":"Contributing to kerasnip","text":"recommend create Git branch pull request (PR). Look GitHub Actions build status making changes. README contains badges continuous integration services used package. New code follow tidyverse style guide. can use air package apply styles. can format code automatically commenting /style PR. use roxygen2, Markdown syntax, documentation. use testthat. Contributions test cases included easier accept. user-facing changes, add bullet top NEWS.md current development version header describing changes made followed GitHub username, links relevant issue(s)/PR(s).","code":""},{"path":"https://davidrsch.github.io/kerasnip/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to kerasnip","text":"Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":[]},{"path":"https://davidrsch.github.io/kerasnip/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 kerasnip authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://davidrsch.github.io/kerasnip/SUPPORT.html","id":null,"dir":"","previous_headings":"","what":"Getting help with kerasnip","title":"Getting help with kerasnip","text":"Thanks using kerasnip. filing issue, places explore pieces put together make process smooth possible. Start making minimal reproducible example using reprex package. haven’t heard used reprex , ’re treat! Seriously, reprex make R-question-asking endeavors easier (pretty insane ROI five ten minutes ’ll take learn ’s ). additional reprex pointers, check Get help! section tidyverse site. Armed reprex, next step figure ask. ’s question: start community.rstudio.com, /StackOverflow. people answer questions. ’s bug: ’re right place, file issue. ’re sure: let community help figure ! problem bug feature request, can easily return report . opening new issue, sure search issues pull requests make sure bug hasn’t reported /already fixed development version. default, search pre-populated :issue :open. can edit qualifiers (e.g. :pr, :closed) needed. example, ’d simply remove :open search issues repo, open closed. right place, need file issue, please review “File issues” paragraph tidyverse contributing guidelines. Thanks help!","code":""},{"path":"https://davidrsch.github.io/kerasnip/articles/getting-started.html","id":"the-core-idea-from-keras-layers-to-tidymodels-specs","dir":"Articles","previous_headings":"","what":"The Core Idea: From Keras Layers to Tidymodels Specs","title":"Getting Started with kerasnip","text":"keras package allows building deep learning models layer--layer, powerful flexible approach. However, tidymodels ecosystem designed around declarative model specifications, define model want parameters want tune, rather building imperatively. kerasnip bridges gap simple powerful concept: layer blocks. define components neural network (e.g., input block, dense block, dropout block) simple R functions. kerasnip uses blocks building materials create brand new parsnip model specification function . new function behaves just like parsnip model (e.g., rand_forest() linear_reg()), making easy integrate workflows tune tune. ’ll start loading kerasnip, tidymodels keras3:","code":"library(kerasnip) library(tidymodels) ## ── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ── ## ✔ broom        1.0.8     ✔ recipes      1.3.1 ## ✔ dials        1.4.0     ✔ rsample      1.3.0 ## ✔ dplyr        1.1.4     ✔ tibble       3.3.0 ## ✔ ggplot2      3.5.2     ✔ tidyr        1.3.1 ## ✔ infer        1.0.9     ✔ tune         1.3.0 ## ✔ modeldata    1.4.0     ✔ workflows    1.2.0 ## ✔ parsnip      1.3.2     ✔ workflowsets 1.1.1 ## ✔ purrr        1.1.0     ✔ yardstick    1.3.2 ## ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ── ## ✖ purrr::discard() masks scales::discard() ## ✖ dplyr::filter()  masks stats::filter() ## ✖ dplyr::lag()     masks stats::lag() ## ✖ recipes::step()  masks stats::step() library(keras3) ##  ## Attaching package: 'keras3' ## The following object is masked from 'package:yardstick': ##  ##     get_weights"},{"path":"https://davidrsch.github.io/kerasnip/articles/getting-started.html","id":"example-1-building-and-fitting-a-basic-mlp","dir":"Articles","previous_headings":"","what":"Example 1: Building and Fitting a Basic MLP","title":"Getting Started with kerasnip","text":"Let’s start building simple Multi-Layer Perceptron (MLP) regression task using mtcars dataset.","code":""},{"path":"https://davidrsch.github.io/kerasnip/articles/getting-started.html","id":"step-1-define-the-layer-blocks","dir":"Articles","previous_headings":"Example 1: Building and Fitting a Basic MLP","what":"Step 1: Define the Layer Blocks","title":"Getting Started with kerasnip","text":"need three blocks: 1. input block initialize model define input shape. kerasnip automatically pass input_shape argument fitting. 2. dense block hidden layers. ’ll give units argument can control number neurons. 3. output block final prediction. regression, typically single neuron linear activation.","code":"# 1. The input block must initialize the model.  # input_shape is passed automatically by the fit engine.  mlp_input_block <- function(model, input_shape) {   keras_model_sequential(input_shape = input_shape)  }  # 2. A block for hidden layers. units will become a tunable parameter.  mlp_dense_block <- function(model, units = 32) {   model |>     layer_dense(units = units, activation = \"relu\")  }  # 3. The output block for a regression model.  mlp_output_block <- function(model) {   model |>     layer_dense(units = 1)  }"},{"path":"https://davidrsch.github.io/kerasnip/articles/getting-started.html","id":"step-2-create-the-model-specification","dir":"Articles","previous_headings":"Example 1: Building and Fitting a Basic MLP","what":"Step 2: Create the Model Specification","title":"Getting Started with kerasnip","text":"Now, use create_keras_spec() generate new model function, ’ll call basic_mlp(). provide layer blocks order assembled. function call side-effect: new function basic_mlp() now available environment! Notice arguments: kerasnipautomatically created num_dense (control number dense layers) dense_units (units argument mlp_dense_block).","code":"create_keras_spec(   model_name = \"basic_mlp\",   layer_blocks = list(     input = mlp_input_block,     dense = mlp_dense_block,     output = mlp_output_block   ),   mode = \"regression\"  )"},{"path":"https://davidrsch.github.io/kerasnip/articles/getting-started.html","id":"step-3-use-the-spec-in-a-workflow","dir":"Articles","previous_headings":"Example 1: Building and Fitting a Basic MLP","what":"Step 3: Use the Spec in a Workflow","title":"Getting Started with kerasnip","text":"can now use basic_mlp() like parsnip model. Let’s define model two hidden layers, 64 units, train 50 epochs. ’ll use simple recipe normalize predictors combine model spec workflow.","code":"spec <- basic_mlp(   num_dense = 2,   dense_units = 64,   epochs = 50,   learn_rate = 0.01  ) |>   set_engine(\"keras\")  print(spec) ## basic mlp Model Specification (regression) ##  ## Main Arguments: ##   num_input = structure(list(), class = \"rlang_zap\") ##   num_dense = 2 ##   num_output = structure(list(), class = \"rlang_zap\") ##   dense_units = 64 ##   epochs = 50 ##   batch_size = structure(list(), class = \"rlang_zap\") ##   learn_rate = 0.01 ##   validation_split = structure(list(), class = \"rlang_zap\") ##   verbose = structure(list(), class = \"rlang_zap\") ##   compile_loss = structure(list(), class = \"rlang_zap\") ##   compile_optimizer = structure(list(), class = \"rlang_zap\") ##   compile_metrics = structure(list(), class = \"rlang_zap\") ##  ## Computational engine: keras # Suppress verbose Keras output for the vignette  options(keras.fit_verbose = 0)    rec <- recipe(mpg ~ ., data = mtcars) |>   step_normalize(all_numeric_predictors())  wf <- workflow() |>   add_recipe(rec) |>   add_model(spec)  set.seed(123)  fit_obj <- fit(wf, data = mtcars)"},{"path":"https://davidrsch.github.io/kerasnip/articles/getting-started.html","id":"step-4-make-predictions","dir":"Articles","previous_headings":"Example 1: Building and Fitting a Basic MLP","what":"Step 4: Make Predictions","title":"Getting Started with kerasnip","text":"Predictions work just ’d expect tidymodels.","code":"predictions <- predict(fit_obj, new_data = mtcars[1:5, ]) ## 1/1 - 0s - 39ms/step print(predictions) ## # A tibble: 5 × 1 ##   .pred ##   <dbl> ## 1  21.6 ## 2  20.4 ## 3  26.2 ## 4  18.8 ## 5  17.7"},{"path":"https://davidrsch.github.io/kerasnip/articles/getting-started.html","id":"example-2-tuning-the-model-architecture","dir":"Articles","previous_headings":"","what":"Example 2: Tuning the Model Architecture","title":"Getting Started with kerasnip","text":"real power kerasnip comes ability tune just hyperparameters (like learning rate dropout), architecture network . Let’s create complex tunable specification let tune find optimal number dense layers, number units layers, rate final dropout layer.","code":""},{"path":"https://davidrsch.github.io/kerasnip/articles/getting-started.html","id":"step-1-define-blocks-and-create-a-new-spec","dir":"Articles","previous_headings":"Example 2: Tuning the Model Architecture","what":"Step 1: Define Blocks and Create a New Spec","title":"Getting Started with kerasnip","text":"First, ’ll define additional block dropout create new model specification, tunable_mlp, includes .","code":"tunable_dropout_block <- function(model, rate = 0.2) {   model |>     layer_dropout(rate = rate) }  create_keras_spec(   model_name = \"tunable_mlp\",   layer_blocks = list(     input = mlp_input_block,     dense = mlp_dense_block,     dropout = tunable_dropout_block,     output = mlp_output_block   ),   mode = \"regression\" )"},{"path":"https://davidrsch.github.io/kerasnip/articles/getting-started.html","id":"step-2-define-a-tunable-specification","dir":"Articles","previous_headings":"Example 2: Tuning the Model Architecture","what":"Step 2: Define a Tunable Specification","title":"Getting Started with kerasnip","text":"use new tunable_mlp() function, passing tune() arguments want optimize. one dropout layer output.","code":"tune_spec <- tunable_mlp(   num_dense = tune(),   dense_units = tune(),   num_dropout = 1,   dropout_rate = tune(),   epochs = 20 # Use fewer epochs for faster tuning  ) |>   set_engine(\"keras\")  print(tune_spec) ## tunable mlp Model Specification (regression) ##  ## Main Arguments: ##   num_input = structure(list(), class = \"rlang_zap\") ##   num_dense = tune() ##   num_dropout = 1 ##   num_output = structure(list(), class = \"rlang_zap\") ##   dense_units = tune() ##   dropout_rate = tune() ##   epochs = 20 ##   batch_size = structure(list(), class = \"rlang_zap\") ##   learn_rate = structure(list(), class = \"rlang_zap\") ##   validation_split = structure(list(), class = \"rlang_zap\") ##   verbose = structure(list(), class = \"rlang_zap\") ##   compile_loss = structure(list(), class = \"rlang_zap\") ##   compile_optimizer = structure(list(), class = \"rlang_zap\") ##   compile_metrics = structure(list(), class = \"rlang_zap\") ##  ## Computational engine: keras"},{"path":"https://davidrsch.github.io/kerasnip/articles/getting-started.html","id":"step-3-set-up-the-tuning-grid","dir":"Articles","previous_headings":"Example 2: Tuning the Model Architecture","what":"Step 3: Set up the Tuning Grid","title":"Getting Started with kerasnip","text":"create workflow . , can use helper functions dials define search space parameters.","code":"tune_wf <- workflow() |>   add_recipe(rec) |>   add_model(tune_spec)  # Define the tuning grid.  # `num_terms()` is the dials function for `num_*` parameters. # `hidden_units()` is the dials function for `*_units` parameters. params <- extract_parameter_set_dials(tune_wf) |>   update(     num_dense = dials::num_terms(c(1, 3)),     dense_units = dials::hidden_units(c(8, 64)),     dropout_rate = dials::dropout(c(0.1, 0.5))   ) grid <- grid_regular(params, levels = 2)  print(grid) ## # A tibble: 8 × 3 ##   num_dense dense_units dropout_rate ##       <int>       <int>        <dbl> ## 1         1           8          0.1 ## 2         3           8          0.1 ## 3         1          64          0.1 ## 4         3          64          0.1 ## 5         1           8          0.5 ## 6         3           8          0.5 ## 7         1          64          0.5 ## 8         3          64          0.5"},{"path":"https://davidrsch.github.io/kerasnip/articles/getting-started.html","id":"step-4-run-the-tuning","dir":"Articles","previous_headings":"Example 2: Tuning the Model Architecture","what":"Step 4: Run the Tuning","title":"Getting Started with kerasnip","text":"use tune_grid() resamples evaluate combination architectural parameters.","code":"set.seed(456)  folds <- vfold_cv(mtcars, v = 3)    # The control argument is used to prevent saving predictions, which  # can be large for Keras models.  tune_res <- tune_grid(   tune_wf,   resamples = folds,   grid = grid,   control = control_grid(save_pred = FALSE)  ) ## 1/1 - 0s - 36ms/step ## 1/1 - 0s - 41ms/step ## 1/1 - 0s - 34ms/step ## 1/1 - 0s - 41ms/step ## 1/1 - 0s - 34ms/step ## 1/1 - 0s - 41ms/step ## 1/1 - 0s - 34ms/step ## 1/1 - 0s - 41ms/step ## 1/1 - 0s - 33ms/step ## 1/1 - 0s - 44ms/step ## 1/1 - 0s - 34ms/step ## 1/1 - 0s - 41ms/step ## 1/1 - 0s - 34ms/step ## 1/1 - 0s - 41ms/step ## 1/1 - 0s - 34ms/step ## 1/1 - 0s - 41ms/step ## 1/1 - 0s - 35ms/step ## 1/1 - 0s - 41ms/step ## 1/1 - 0s - 34ms/step ## 1/1 - 0s - 42ms/step ## 1/1 - 0s - 34ms/step ## 1/1 - 0s - 43ms/step ## 1/1 - 0s - 34ms/step ## 1/1 - 0s - 42ms/step"},{"path":"https://davidrsch.github.io/kerasnip/articles/getting-started.html","id":"step-5-analyze-the-results","dir":"Articles","previous_headings":"Example 2: Tuning the Model Architecture","what":"Step 5: Analyze the Results","title":"Getting Started with kerasnip","text":"can now see architecture performed best. results show tune successfully tested different network depths (num_dense), widths (dense_units), dropout rates find best-performing combination. demonstrates kerasnip seamlessly integrates complex architectural tuning standard tidymodels workflow.","code":"show_best(tune_res, metric = \"rmse\") ## # A tibble: 5 × 9 ##   num_dense dense_units dropout_rate .metric .estimator  mean     n std_err ##       <int>       <int>        <dbl> <chr>   <chr>      <dbl> <int>   <dbl> ## 1         3          64          0.1 rmse    standard    4.45     3   0.770 ## 2         3          64          0.5 rmse    standard    5.88     3   0.701 ## 3         1          64          0.5 rmse    standard   10.4      3   0.533 ## 4         1          64          0.1 rmse    standard   10.6      3   0.226 ## 5         3           8          0.1 rmse    standard   13.0      3   2.08  ## # ℹ 1 more variable: .config <chr>"},{"path":"https://davidrsch.github.io/kerasnip/articles/getting-started.html","id":"advanced-customization","dir":"Articles","previous_headings":"","what":"Advanced Customization","title":"Getting Started with kerasnip","text":"kerasnip provides clean API passing arguments directly Keras’s compile() fit() methods. Compile Arguments: Pass argument keras3::compile() prefixing compile_. example, change loss function use compile_loss = \"mae\". Fit Arguments: Pass argument keras3::fit() prefixing fit_. example, set validation split add callback, use fit_validation_split = 0.2 fit_callbacks = list(...). example using arguments specify different loss function, validation split, early stopping callback. system gives full control Keras training process keeping model specification function signature clean focused tunable parameters.","code":"adv_spec <- basic_mlp(   num_dense = 2,   dense_units = 32,   epochs = 100,   # Arguments for keras3::compile()   compile_loss = \"mae\",   # Arguments for keras3::fit()   fit_validation_split = 0.2,   fit_callbacks = list(     keras3::callback_early_stopping(patience = 5)   ) ) |>   set_engine(\"keras\")  print(adv_spec) ## basic mlp Model Specification (regression) ##  ## Main Arguments: ##   num_input = structure(list(), class = \"rlang_zap\") ##   num_dense = 2 ##   num_output = structure(list(), class = \"rlang_zap\") ##   dense_units = 32 ##   epochs = 100 ##   batch_size = structure(list(), class = \"rlang_zap\") ##   learn_rate = structure(list(), class = \"rlang_zap\") ##   validation_split = structure(list(), class = \"rlang_zap\") ##   verbose = structure(list(), class = \"rlang_zap\") ##   compile_loss = mae ##   compile_optimizer = structure(list(), class = \"rlang_zap\") ##   compile_metrics = structure(list(), class = \"rlang_zap\") ##   fit_validation_split = 0.2 ##   fit_callbacks = list(keras3::callback_early_stopping(patience = 5)) ##  ## Computational engine: keras"},{"path":"https://davidrsch.github.io/kerasnip/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David Díaz. Author, maintainer.","code":""},{"path":"https://davidrsch.github.io/kerasnip/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Díaz D (2025). kerasnip: Bridge Keras Tidymodels. R package version 0.0.0.9000.","code":"@Manual{,   title = {kerasnip: A Bridge Between Keras and Tidymodels},   author = {David Díaz},   year = {2025},   note = {R package version 0.0.0.9000}, }"},{"path":"https://davidrsch.github.io/kerasnip/index.html","id":"kerasnip","dir":"","previous_headings":"","what":"A Bridge Between Keras and Tidymodels","title":"A Bridge Between Keras and Tidymodels","text":"goal kerasnip provide seamless bridge keras tidymodels ecosystems. allows dynamic creation parsnip model specifications Keras models, making fully compatible tidymodels workflows.","code":""},{"path":"https://davidrsch.github.io/kerasnip/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A Bridge Between Keras and Tidymodels","text":"can install development version kerasnip GitHub :","code":"# install.packages(\"pak\") pak::pak(\"davidrsch/kerasnip\")"},{"path":[]},{"path":"https://davidrsch.github.io/kerasnip/index.html","id":"example-building-a-sequential-mlp-from-layer-blocks","dir":"","previous_headings":"Example","what":"Example: Building a Sequential MLP from Layer Blocks","title":"A Bridge Between Keras and Tidymodels","text":"example shows core kerasnip workflow building model modular “layer blocks”. : 1. Define reusable blocks Keras layers. 2. Create model specification blocks. 3. Fit model fixed architecture.","code":"library(kerasnip) library(tidymodels) library(keras3)  # 1. Define Keras layer blocks # Each block is a function that takes a Keras model object and adds layers. # The first block in the sequence is responsible for initializing the model. mlp_input_block <- function(model, input_shape) {   keras_model_sequential(input_shape = input_shape) }  mlp_dense_block <- function(model, units = 32) {   model |>     layer_dense(units = units, activation = \"relu\") }  mlp_output_block <- function(model) {   model |>     layer_dense(units = 1) }  # 2. Create a spec from the layer blocks # This creates a new model function, `basic_mlp()`, in your environment. create_keras_spec(   model_name = \"basic_mlp\",   layer_blocks = list(     input = mlp_input_block,     dense = mlp_dense_block,     output = mlp_output_block   ),   mode = \"regression\" )  # 3. Use the generated spec to define and fit a model # We can set the number of dense layers (`num_dense`) and their parameters # (`dense_units`). spec <- basic_mlp(   num_dense = 2,   dense_units = 64,   epochs = 50,   learn_rate = 0.01 ) |>   set_engine(\"keras\")  # 4. Fit the model within a tidymodels workflow rec <- recipe(mpg ~ ., data = mtcars) |>   step_normalize(all_numeric_predictors())  wf <- workflow() |>   add_recipe(rec) |>   add_model(spec)  set.seed(123) fit_obj <- fit(wf, data = mtcars)  # 5. Make predictions predictions <- predict(fit_obj, new_data = mtcars[1:5, ]) print(predictions) #> # A tibble: 5 × 1 #>   .pred #>   <dbl> #> 1  22.6 #> 2  20.9 #> 3  26.1 #> 4  19.7 #> 5  17.8"},{"path":"https://davidrsch.github.io/kerasnip/index.html","id":"example-tuning-a-sequential-mlp-architecture","dir":"","previous_headings":"Example","what":"Example: Tuning a Sequential MLP Architecture","title":"A Bridge Between Keras and Tidymodels","text":"example demonstrates tune number dense layers rate final dropout layer, showcasing tune architecture block hyperparameters simultaneously.","code":"library(kerasnip) library(tidymodels) library(keras3)  # 1. Define Keras layer blocks for a tunable MLP mlp_input_block <- function(model, input_shape) {   keras_model_sequential(input_shape = input_shape) }  tunable_dense_block <- function(model, units = 32) {   model |> layer_dense(units = units, activation = \"relu\") }  tunable_dropout_block <- function(model, rate = 0.2) {   model |> layer_dropout(rate = rate) }  mlp_output_block <- function(model) {   model |> layer_dense(units = 1) }  # 2. Create a spec from the layer blocks create_keras_spec(   model_name = \"tunable_mlp\",   layer_blocks = list(     input = mlp_input_block,     dense = tunable_dense_block,     dropout = tunable_dropout_block,     output = mlp_output_block   ),   mode = \"regression\" )  # 3. Define a tunable model specification tune_spec <- tunable_mlp(   num_dense = tune(),   dense_units = tune(),   num_dropout = 1,   dropout_rate = tune(),   epochs = 20 ) |>   set_engine(\"keras\")  # 4. Set up a tuning workflow rec <- recipe(mpg ~ ., data = mtcars) |>   step_normalize(all_numeric_predictors())  wf_tune <- workflow() |>   add_recipe(rec) |>   add_model(tune_spec)  # Define the tuning grid. params <- extract_parameter_set_dials(wf_tune) |>   update(     num_dense = dials::num_terms(c(1, 3)),     dense_units = dials::hidden_units(c(8, 64)),     dropout_rate = dials::dropout(c(0.1, 0.5))   ) grid <- grid_regular(params, levels = 2)  # 5. Run the tuning set.seed(456) folds <- vfold_cv(mtcars, v = 3)  tune_res <- tune_grid(   wf_tune,   resamples = folds,   grid = grid )  # 6. Show the best architecture show_best(tune_res, metric = \"rmse\") #> # A tibble: 5 × 7 #>   num_dense dense_units dropout_rate .metric .estimator .mean .config               #>       <int>       <int>        <dbl> <chr>   <chr>      <dbl> <chr>                 #> 1         1          64          0.1 rmse    standard    2.92 Preprocessor1_Model02 #> 2         1          64          0.5 rmse    standard    3.02 Preprocessor1_Model08 #> 3         3          64          0.1 rmse    standard    3.15 Preprocessor1_Model04 #> 4         1           8          0.1 rmse    standard    3.20 Preprocessor1_Model01 #> 5         3           8          0.1 rmse    standard    3.22 Preprocessor1_Model03"},{"path":"https://davidrsch.github.io/kerasnip/reference/create_keras_spec.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Custom Keras Model Specification for Tidymodels — create_keras_spec","title":"Create a Custom Keras Model Specification for Tidymodels — create_keras_spec","text":"function acts factory generate new parsnip model specification based user-defined blocks Keras layers. allows creating complex, tunable architectures integrate seamlessly tidymodels ecosystem.","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/create_keras_spec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Custom Keras Model Specification for Tidymodels — create_keras_spec","text":"","code":"create_keras_spec(   model_name,   layer_blocks,   mode = c(\"regression\", \"classification\"),   ...,   env = parent.frame() )"},{"path":"https://davidrsch.github.io/kerasnip/reference/create_keras_spec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Custom Keras Model Specification for Tidymodels — create_keras_spec","text":"model_name character string name new model specification function (e.g., \"custom_cnn\"). valid R function name. layer_blocks named list functions. function defines \"block\" Keras layers. function must take Keras model object first argument return modified model. arguments function become tunable parameters final model specification. mode character string, either \"regression\" \"classification\". ... Reserved future use. Currently used. env environment create new model specification function associated update() method. Defaults calling environment (parent.frame()).","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/create_keras_spec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Custom Keras Model Specification for Tidymodels — create_keras_spec","text":"Invisibly returns NULL. primary side effect create new model specification function (e.g., dynamic_mlp()) specified environment register model parsnip can used within tidymodels framework.","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/create_keras_spec.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Custom Keras Model Specification for Tidymodels — create_keras_spec","text":"user responsible defining entire model architecture providing ordered list layer block functions. first block function must initialize model (e.g., keras_model_sequential()). can accept input_shape argument, provided automatically fitting engine. Subsequent blocks add hidden layers. final block add output layer. classification, can accept num_classes argument, provided automatically. create_keras_spec() function inspect arguments layer_blocks functions (ignoring input_shape num_classes) make available arguments generated model specification, prefixed block's name (e.g., dense_units). also automatically creates arguments like num_dense control many times block repeated. addition, common training parameters epochs, learn_rate, validation_split, verbose added specification. new model specification function update() method created environment specified env argument.","code":""},{"path":[]},{"path":"https://davidrsch.github.io/kerasnip/reference/create_keras_spec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Custom Keras Model Specification for Tidymodels — create_keras_spec","text":"","code":"if (FALSE) { # \\dontrun{ if (requireNamespace(\"keras3\", quietly = TRUE)) { library(keras3) library(parsnip) library(dials)  # 1. Define layer blocks for a complete model. # The first block must initialize the model. `input_shape` is passed automatically. input_block <- function(model, input_shape) {   keras_model_sequential(input_shape = input_shape) } # A block for hidden layers. `units` will become a tunable parameter. hidden_block <- function(model, units = 32) {   model |> layer_dense(units = units, activation = \"relu\") }  # The output block. `num_classes` is passed automatically for classification. output_block <- function(model, num_classes) {   model |> layer_dense(units = num_classes, activation = \"softmax\") }  # 2. Create the spec, providing blocks in the correct order. create_keras_spec( model_name = \"my_mlp\",   layer_blocks = list(     input = input_block,     hidden = hidden_block,     output = output_block   ),   mode = \"classification\" )  # 3. Use the newly created specification function! model_spec <- my_mlp(   num_hidden = 2,   hidden_units = 64,   epochs = 10,   learn_rate = 0.01 )  print(model_spec) } } # }"},{"path":"https://davidrsch.github.io/kerasnip/reference/generic_keras_fit_impl.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic Keras Model Fitting Implementation — generic_keras_fit_impl","title":"Generic Keras Model Fitting Implementation — generic_keras_fit_impl","text":"function internal engine fitting models generated create_keras_spec(). intended called directly user.","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/generic_keras_fit_impl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic Keras Model Fitting Implementation — generic_keras_fit_impl","text":"","code":"generic_keras_fit_impl(   x,   y,   layer_blocks,   epochs = 10,   batch_size = 32,   learn_rate = 0.01,   validation_split = 0.2,   verbose = 0,   ... )"},{"path":"https://davidrsch.github.io/kerasnip/reference/generic_keras_fit_impl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic Keras Model Fitting Implementation — generic_keras_fit_impl","text":"x data frame matrix predictors. y vector outcomes. layer_blocks named list layer block functions. passed internally parsnip model specification. epochs integer number training iterations. batch_size integer number samples per gradient update. tunable parameter passed keras3::fit(). learn_rate double learning rate, used configure default Adam optimizer. validation_split proportion training data use validation set. verbose integer verbosity fitting process (0, 1, 2). ... Additional arguments passed model specification. can include: Layer Parameters: Arguments layer blocks, prefixed block name (e.g., dense_units = 64). Architecture Parameters: Arguments control number times block repeated, format num_{block_name} (e.g., num_dense = 2). Compile Parameters: Arguments customize model compilation, prefixed compile_ (e.g., compile_loss = \"mae\", compile_optimizer = \"sgd\"). Fit Parameters: Arguments customize model fitting, prefixed fit_ (e.g., fit_callbacks = list(...), fit_class_weight = list(...)).","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/generic_keras_fit_impl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generic Keras Model Fitting Implementation — generic_keras_fit_impl","text":"parsnip model fit object.","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/generic_keras_fit_impl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generic Keras Model Fitting Implementation — generic_keras_fit_impl","text":"function performs several key steps: Argument & Data Preparation: resolves arguments parsnip prepares x y data Keras. automatically determines input_shape x , classification, num_classes y. Dynamic Model Construction: user responsible defining entire model architecture via layer_blocks. function iterates blocks order provided: first block function must initialize model, typically calling keras3::keras_model_sequential(). can accept input_shape argument, provided automatically. Subsequent blocks receive model add layers . output layer block can accept num_classes argument, provided automatically classification models. Model Compilation: compiles final Keras model. compilation arguments (optimizer, loss, metrics) can customized: Override defaults passing arguments prefixed compile_ (e.g., compile_loss = \"mae\", compile_optimizer = \"sgd\"). Model Fitting: calls keras3::fit() train model prepared data.","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/keras_objects.html","id":null,"dir":"Reference","previous_headings":"","what":"Dynamically Discovered Keras Objects — keras_objects","title":"Dynamically Discovered Keras Objects — keras_objects","text":"vectors contain names optimizers, losses, metrics discovered installed keras3 package load time. ensures kerasnip always --date Keras version.","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/keras_objects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dynamically Discovered Keras Objects — keras_objects","text":"","code":"keras_optimizers  keras_losses  keras_metrics"},{"path":"https://davidrsch.github.io/kerasnip/reference/keras_objects.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dynamically Discovered Keras Objects — keras_objects","text":"object class character length 12. object class character length 21. object class character length 32.","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/loss_function_keras.html","id":null,"dir":"Reference","previous_headings":"","what":"Dials Parameter for Keras Loss Functions — loss_function_keras","title":"Dials Parameter for Keras Loss Functions — loss_function_keras","text":"Dials Parameter Keras Loss Functions","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/loss_function_keras.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dials Parameter for Keras Loss Functions — loss_function_keras","text":"","code":"loss_function_keras(values = NULL)"},{"path":"https://davidrsch.github.io/kerasnip/reference/loss_function_keras.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dials Parameter for Keras Loss Functions — loss_function_keras","text":"values character vector possible loss functions. Defaults known losses (keras defaults + custom registered).","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/optimizer_function.html","id":null,"dir":"Reference","previous_headings":"","what":"Dials Parameter for Keras Optimizers — optimizer_function","title":"Dials Parameter for Keras Optimizers — optimizer_function","text":"Dials Parameter Keras Optimizers","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/optimizer_function.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dials Parameter for Keras Optimizers — optimizer_function","text":"","code":"optimizer_function(values = NULL)"},{"path":"https://davidrsch.github.io/kerasnip/reference/optimizer_function.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dials Parameter for Keras Optimizers — optimizer_function","text":"values character vector possible optimizers. Defaults known optimizers (keras defaults + custom registered).","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/register_keras_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Register a Custom Keras Loss — register_keras_loss","title":"Register a Custom Keras Loss — register_keras_loss","text":"Register Custom Keras Loss","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/register_keras_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Register a Custom Keras Loss — register_keras_loss","text":"","code":"register_keras_loss(name, loss_fn)"},{"path":"https://davidrsch.github.io/kerasnip/reference/register_keras_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Register a Custom Keras Loss — register_keras_loss","text":"name name register loss (character). loss_fn loss function.","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/register_keras_metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Register a Custom Keras Metric — register_keras_metric","title":"Register a Custom Keras Metric — register_keras_metric","text":"Register Custom Keras Metric","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/register_keras_metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Register a Custom Keras Metric — register_keras_metric","text":"","code":"register_keras_metric(name, metric_fn)"},{"path":"https://davidrsch.github.io/kerasnip/reference/register_keras_metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Register a Custom Keras Metric — register_keras_metric","text":"name name register metric (character). metric_fn metric function.","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/register_keras_optimizer.html","id":null,"dir":"Reference","previous_headings":"","what":"Register a Custom Keras Optimizer — register_keras_optimizer","title":"Register a Custom Keras Optimizer — register_keras_optimizer","text":"Register Custom Keras Optimizer","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/register_keras_optimizer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Register a Custom Keras Optimizer — register_keras_optimizer","text":"","code":"register_keras_optimizer(name, optimizer_fn)"},{"path":"https://davidrsch.github.io/kerasnip/reference/register_keras_optimizer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Register a Custom Keras Optimizer — register_keras_optimizer","text":"name name register optimizer (character). optimizer_fn optimizer function (e.g., custom function partially applied keras optimizer).","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/remove_keras_spec.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove a Keras Model Specification — remove_keras_spec","title":"Remove a Keras Model Specification — remove_keras_spec","text":"function removes model specification function previously created create_keras_spec() environment.","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/remove_keras_spec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove a Keras Model Specification — remove_keras_spec","text":"","code":"remove_keras_spec(model_name, env = parent.frame())"},{"path":"https://davidrsch.github.io/kerasnip/reference/remove_keras_spec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove a Keras Model Specification — remove_keras_spec","text":"model_name character string giving name model specification function remove. env environment remove function. Defaults calling environment (parent.frame()), typically create_keras_spec() created function.","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/remove_keras_spec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove a Keras Model Specification — remove_keras_spec","text":"Invisibly returns TRUE function found removed, FALSE otherwise.","code":""},{"path":"https://davidrsch.github.io/kerasnip/reference/remove_keras_spec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove a Keras Model Specification — remove_keras_spec","text":"","code":"if (FALSE) { # \\dontrun{ # First, create a dummy spec dense_block <- function(model, units = 16) {   model |> keras3::layer_dense(units = units) } create_keras_spec(\"my_temp_model\", list(dense = dense_block), \"regression\")  # Check it exists exists(\"my_temp_model\")  # Now remove it remove_keras_spec(\"my_temp_model\")  # Check it's gone !exists(\"my_temp_model\") } # }"},{"path":"https://davidrsch.github.io/kerasnip/news/index.html","id":"kerasnip-0009000","dir":"Changelog","previous_headings":"","what":"kerasnip 0.0.0.9000","title":"kerasnip 0.0.0.9000","text":"Initial development version. Added create_keras_spec() generate parsnip specifications dynamically.","code":""}]
